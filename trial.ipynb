{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install playsound\n",
    "#%pip install tensorflow --user\n",
    "#%pip install librosa\n",
    "#%pip install torch --user\n",
    "#%pip install optuna --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n",
    "import librosa\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import IPython.display as ipd\n",
    "from playsound import playsound\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch, gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The acceleration is on: \", device)\n",
    "stringLabels = [\"SAD\", \"ANG\", \"NEU\", \"HAP\", \"FEA\", \"DIS\"]\n",
    "labelToIndex = {stringLabels[i]: i for i in range(len(stringLabels))}\n",
    "files = np.array([])\n",
    "labels = np.array([])\n",
    "maxLen = 110361\n",
    "for dirname, _, filenames in os.walk('dataset'):\n",
    "    for filename in filenames:\n",
    "        # Reading the wav file\n",
    "        if filename.endswith('.wav'):\n",
    "            # Read the wav file (mono)\n",
    "            files = np.append(files, os.path.join(dirname, filename))\n",
    "            labels = np.append(labels, filename.split(\"_\")[2])\n",
    "def playAudio(path):\n",
    "    playsound(path)\n",
    "\n",
    "def getSamplingFrequency(path):\n",
    "    fileData = wave.open(path, 'rb')\n",
    "    # Extract Raw Audio from Wav File\n",
    "    signal = fileData.readframes(-1)\n",
    "    signal = np.frombuffer(signal, dtype='int16')\n",
    "    # Get the frame rate\n",
    "    frameRate = fileData.getframerate()\n",
    "    return frameRate\n",
    "\n",
    "def getAudioSignal(path):\n",
    "    fileData = wave.open(path, 'rb')\n",
    "    # Extract Raw Audio from Wav File\n",
    "    signal = fileData.readframes(-1)\n",
    "    signal = np.frombuffer(signal, dtype='int16')\n",
    "    # Get the frame rate\n",
    "    frameRate = fileData.getframerate()\n",
    "    # Find the time of the audio file\n",
    "    time = np.linspace(0, len(signal) / frameRate, num=len(signal))\n",
    "    return signal, time\n",
    "\n",
    "\n",
    "def calculateZeroCrossingRate(audioPath, frameSize, hopSize):\n",
    "    audio, sr = librosa.load(audioPath, sr=None)# we can make mono = True to convert it to 1 channel only\n",
    "    return np.array(librosa.feature.zero_crossing_rate( y= audio, frame_length= frameSize, hop_length= hopSize)[0]) # We can make center=True to get more accurate results\n",
    "\n",
    "def calculateEnergy(audioPath, frameSize, hopSize):\n",
    "    \"\"\"\n",
    "    audioPath: The path of the audio file\n",
    "    frameSize: The number of samples in each frame\n",
    "    hopSize: The number of samples between successive frames\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(audioPath, sr=None)# we can make mono = True to convert it to 1 channel only\n",
    "    return np.array(librosa.feature.rms(y = audio, frame_length= frameSize, hop_length= hopSize)[0] ** 2) # We can make center=True to get more accurate results\n",
    "\n",
    "def calculateMelSpectogram(audioPath, n_fft, hopSize, n_mels):\n",
    "    \"\"\"\"\n",
    "    n_fft: The number of points in the FFT, which determines the frequency resolution of the spectrogram\n",
    "    hopSize: The number of samples between successive frames\n",
    "    n_mels: The number of mel frequency bands to generate in the spectrogram or the number of filters in the filterbank\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(audioPath, sr=None)# we can make mono = True to convert it to 1 channel only\n",
    "    mel_spec = librosa.feature.melspectrogram(y= audio, sr=sr, n_fft=n_fft, hop_length=hopSize, n_mels=n_mels)\n",
    "    mel_spec_db  = librosa.power_to_db(mel_spec)\n",
    "    # Normalize between 0 and 1\n",
    "    if mel_spec_db.max() - mel_spec_db.min() != 0:\n",
    "        mel_spec_db = (mel_spec_db - mel_spec_db.min()) / ((mel_spec_db.max() - mel_spec_db.min()) + 1e-6) # eps for numerical stability\n",
    "    else:\n",
    "        mel_spec_db = mel_spec_db - mel_spec_db.min()\n",
    "    return mel_spec_db\n",
    "\n",
    "def addNoise(y, sr):\n",
    "    noise = np.random.randn(len(y))\n",
    "    y_noise = y + 0.005 * noise\n",
    "    return y_noise\n",
    "\n",
    "def changeSpeed(y, sr):\n",
    "    speed_change = np.random.uniform(low=0.9, high=1.1)\n",
    "    return librosa.effects.time_stretch(y, rate = speed_change)\n",
    "\n",
    "def timeShift(y, sr):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5) * 1000)\n",
    "    return np.roll(y, shift_range)\n",
    "\n",
    "def pitchShift(y, sr):\n",
    "    pitch_change = int(np.random.randint(low=-3, high = 3))\n",
    "    return librosa.effects.pitch_shift(y, sr = sr, n_steps=pitch_change)\n",
    "\n",
    "def volumeScale(y, sr):\n",
    "    volume_change = np.random.uniform(low=0.5, high = 1.5)\n",
    "    return y * volume_change\n",
    "\n",
    "def augmentData(data, label, savePath, noise, time_shift, change_speed, pitch_shift, volume_scale):\n",
    "    augmentedData = []\n",
    "    augmentedLabel = []\n",
    "    flag = 0\n",
    "    if not os.path.exists(savePath):\n",
    "        os.makedirs(savePath)\n",
    "        flag = 1\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        fileName = data[i][8:23]\n",
    "        \n",
    "        if not flag:\n",
    "            # Appending all of them to the augmentedData\n",
    "            augmentedData.append(data[i])\n",
    "            augmentedLabel.append(label[i])\n",
    "            if noise:\n",
    "                augmentedData.append(savePath+ \"/\" + str(fileName)+\"_noised.wav\")\n",
    "                augmentedLabel.append(label[i])\n",
    "            if change_speed:\n",
    "                augmentedData.append(savePath+ \"/\" + str(fileName)+\"_changeSpeed.wav\")\n",
    "                augmentedLabel.append(label[i])\n",
    "            if time_shift:\n",
    "                augmentedData.append(savePath+ \"/\" + str(fileName)+\"_timeShift.wav\")\n",
    "                augmentedLabel.append(label[i])\n",
    "            if pitch_shift:\n",
    "                augmentedData.append(savePath+ \"/\" + str(fileName)+\"_pitchShift.wav\")\n",
    "                augmentedLabel.append(label[i])\n",
    "            if volume_scale:\n",
    "                augmentedData.append(savePath+ \"/\" + str(fileName)+\"_volumeScale.wav\")\n",
    "                augmentedLabel.append(label[i])\n",
    "            continue\n",
    "        \n",
    "        augmentedData.append(data[i])\n",
    "        augmentedLabel.append(label[i])\n",
    "\n",
    "        audio, sr = librosa.load(data[i], sr=None)\n",
    "        if noise:\n",
    "            noisedAudio = addNoise(audio, sr)\n",
    "            if( maxLen > len(noisedAudio) ):\n",
    "                noisedAudio = np.pad(noisedAudio, (0, maxLen - len(noisedAudio)), 'constant')\n",
    "            noisedAudio = noisedAudio[:maxLen]\n",
    "            sf.write(savePath +  \"/\" + str(fileName)+\"_noised.wav\", noisedAudio, sr)\n",
    "            augmentedData.append(savePath +  \"/\" + str(fileName)+\"_noised.wav\")\n",
    "            augmentedLabel.append(label[i])\n",
    "        if change_speed:\n",
    "            changeSpeedAudio = changeSpeed(audio, sr)\n",
    "            if( maxLen > len(changeSpeedAudio) ):\n",
    "                changeSpeedAudio = np.pad(changeSpeedAudio, (0, maxLen - len(changeSpeedAudio)), 'constant')\n",
    "            changeSpeedAudio = changeSpeedAudio[:maxLen]\n",
    "            sf.write(savePath +  \"/\" + str(fileName)+\"_changeSpeed.wav\", changeSpeedAudio, sr)\n",
    "            augmentedData.append(savePath +  \"/\" + str(fileName)+\"_changeSpeed.wav\")\n",
    "            augmentedLabel.append(label[i])\n",
    "        if time_shift:\n",
    "            timeShiftAudio = timeShift(audio, sr)\n",
    "            if( maxLen > len(timeShiftAudio) ):\n",
    "                timeShiftAudio = np.pad(timeShiftAudio, (0, maxLen - len(timeShiftAudio)), 'constant')\n",
    "            timeShiftAudio = timeShiftAudio[:maxLen]\n",
    "            sf.write(savePath +  \"/\" + str(fileName)+\"_timeShift.wav\", timeShiftAudio, sr)\n",
    "            augmentedData.append(savePath +  \"/\" + str(fileName)+\"_timeShift.wav\")\n",
    "            augmentedLabel.append(label[i])\n",
    "        if pitch_shift:\n",
    "            pitchShiftAudio = pitchShift(audio, sr)\n",
    "            if( maxLen > len(pitchShiftAudio) ):\n",
    "                pitchShiftAudio = np.pad(pitchShiftAudio, (0, maxLen - len(pitchShiftAudio)), 'constant')\n",
    "            pitchShiftAudio = pitchShiftAudio[:maxLen]\n",
    "            sf.write(savePath +  \"/\" + str(fileName)+\"_pitchShift.wav\", pitchShiftAudio, sr)\n",
    "            augmentedData.append(savePath +  \"/\" + str(fileName)+\"_pitchShift.wav\")\n",
    "            augmentedLabel.append(label[i])\n",
    "        if volume_scale:\n",
    "            volumeScaleAudio = volumeScale(audio, sr)\n",
    "            if( maxLen > len(volumeScaleAudio) ):\n",
    "                volumeScaleAudio = np.pad(volumeScaleAudio, (0, maxLen - len(volumeScaleAudio)), 'constant')\n",
    "            volumeScaleAudio = volumeScaleAudio[:maxLen]\n",
    "            sf.write(savePath +  \"/\" + str(fileName)+\"_volumeScale.wav\", volumeScaleAudio, sr)\n",
    "            augmentedData.append(savePath +  \"/\" + str(fileName)+\"_volumeScale.wav\")\n",
    "            augmentedLabel.append(label[i])\n",
    "    return augmentedData, augmentedLabel\n",
    "\n",
    "def plotMelSpectogram(audioPath, n_fft, hopSize, n_mels):\n",
    "    audio, sr = librosa.load(audioPath, sr=None)# we can make mono = True to convert it to 1 channel only\n",
    "    mel_spec = librosa.feature.melspectrogram(y= audio, sr=sr, n_fft=n_fft, hop_length=hopSize, n_mels=n_mels)\n",
    "    mel_spec_db  = librosa.power_to_db(mel_spec)\n",
    "    librosa.display.specshow(mel_spec_db, sr=sr, hop_length=hopSize, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Log Mel spectrogram')\n",
    "    plt.show()\n",
    "\n",
    "def plotSpectrogram(audioPath, time):\n",
    "    audio, sr = librosa.load(audioPath, sr=None)# we can make mono = True to convert it to 1 channel only\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.specgram(audio, Fs=sr)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.show()\n",
    "    \n",
    "def plotSignal(signal, time):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(time, signal)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Audio Signal')\n",
    "    plt.show()\n",
    "\n",
    "def plotHistogram(data, dataTitle):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.hist(data, bins=15)\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of the ' + dataTitle)\n",
    "    plt.show()\n",
    "\n",
    "def extractFeatures(data, labels, n_fft, hopSize, n_mels):\n",
    "    output = np.empty((len(data), 4), dtype=np.ndarray)\n",
    "    \n",
    "    for i, audioFile in enumerate(data):\n",
    "        # Calculate the zero crossing rate\n",
    "        zeroCrossingRate = calculateZeroCrossingRate(audioFile, n_fft, hopSize)\n",
    "        # Calculate the energy\n",
    "        energy = calculateEnergy(audioFile, n_fft, hopSize)\n",
    "        # Calculate the Mel Spectrogram\n",
    "        melSpectrogram = calculateMelSpectogram(audioFile, n_fft, hopSize, n_mels)\n",
    "        # Append the features to the output array\n",
    "        output[i][0] = zeroCrossingRate\n",
    "        output[i][1] = energy\n",
    "        output[i][2] = melSpectrogram\n",
    "        output[i][3] = labels[i]\n",
    "        output[i][0] = output[i][0].reshape(1, output[i][0].shape[0])\n",
    "        output[i][1] = output[i][1].reshape(1, output[i][1].shape[0])\n",
    "    return output\n",
    "\n",
    "def getFeatures(files, labels, n_fft, hopSize, n_mels, noise = False, timeShift = False, changeSpeed = False, pitchShift = False, volumeScale = False):\n",
    "    savingDirectory = \"processed/n_fft_\" + str(N_FFT) + \"_hop_size_\" + str(HOP_SIZE) + \"_n_mels_\" + str(N_MELS)\n",
    "    if noise:\n",
    "        savingDirectory += \"_noise\"\n",
    "    if timeShift:\n",
    "        savingDirectory += \"_timeShift\"\n",
    "    if changeSpeed:\n",
    "        savingDirectory += \"_changeSpeed\"\n",
    "    if pitchShift:\n",
    "        savingDirectory += \"_pitchShift\"\n",
    "    if volumeScale:\n",
    "        savingDirectory += \"_volumeScale\"\n",
    "    if not os.path.exists(savingDirectory):\n",
    "        \n",
    "        x_train_val, x_test, y_train_val, y_test = train_test_split(files, labels, train_size=0.7, random_state=42, stratify=labels)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, train_size=0.95, random_state=42, stratify=y_train_val)\n",
    "        \n",
    "        # Now let's augment the training data \n",
    "        augmentedData, augmentedLabel = augmentData(x_train, y_train, f\"augmented/n_fft_{N_FFT}_hop_size_{HOP_SIZE}_n_mels_{N_MELS}\", noise, timeShift, changeSpeed, pitchShift, volumeScale)\n",
    "        x_train = augmentedData\n",
    "        y_train = augmentedLabel\n",
    "\n",
    "        # Extract the features\n",
    "        x_train = extractFeatures(x_train, y_train, n_fft, hopSize, n_mels)\n",
    "        x_val = extractFeatures(x_val, y_val, n_fft, hopSize, n_mels)\n",
    "        x_test = extractFeatures(x_test, y_test, n_fft, hopSize, n_mels)\n",
    "        \n",
    "        os.makedirs(savingDirectory)\n",
    "        np.save(savingDirectory + \"/x_train.npy\", x_train)\n",
    "        np.save(savingDirectory + \"/x_val.npy\", x_val)\n",
    "        np.save(savingDirectory + \"/x_test.npy\", x_test)\n",
    "        np.save(savingDirectory + \"/y_train.npy\", y_train)\n",
    "        np.save(savingDirectory + \"/y_val.npy\", y_val)\n",
    "        np.save(savingDirectory + \"/y_test.npy\", y_test)\n",
    "    else:\n",
    "        \n",
    "        x_train = np.load(savingDirectory + \"/x_train.npy\", allow_pickle=True)\n",
    "        x_val = np.load(savingDirectory + \"/x_val.npy\", allow_pickle=True)\n",
    "        x_test = np.load(savingDirectory + \"/x_test.npy\", allow_pickle=True)\n",
    "        y_train = np.load(savingDirectory + \"/y_train.npy\", allow_pickle=True)\n",
    "        y_val = np.load(savingDirectory + \"/y_val.npy\", allow_pickle=True)\n",
    "        y_test = np.load(savingDirectory + \"/y_test.npy\", allow_pickle=True)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.zcr = torch.tensor([data[i][0] for i in range(len(data))], dtype=torch.float32)\n",
    "        self.energy = torch.tensor([data[i][1] for i in range(len(data))], dtype=torch.float32)\n",
    "        self.melSpectogram = torch.tensor([data[i][2] for i in range(len(data))], dtype=torch.float32)\n",
    "        \n",
    "        indexLabels = [labelToIndex[labels[i]] for i in range(len(labels))]\n",
    "        oneHotLabels = np.zeros((len(labels), len(stringLabels)))\n",
    "        oneHotLabels[np.arange(len(labels)), indexLabels] = 1\n",
    "        self.labels = torch.tensor(oneHotLabels, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.zcr)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.zcr[idx], self.energy[idx], self.melSpectogram[idx], self.labels[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 512\n",
    "HOP_SIZE = 160\n",
    "N_MELS = 40\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = getFeatures(files=files, labels=labels, n_fft=N_FFT, hopSize = HOP_SIZE, n_mels= N_MELS, noise = True, timeShift = True, changeSpeed = True, pitchShift = True, volumeScale = True)\n",
    "print(\"Extracted Features for the Data Successfully!\")\n",
    "\n",
    "train_dataset = AudioDataset(x_train, y_train)\n",
    "val_dataset = AudioDataset(x_val, y_val)\n",
    "test_dataset = AudioDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.00001\n",
    "LR_DECAY = True\n",
    "LR_DECAY_EPOCH = 30\n",
    "LR_DECAY_FACTOR = 0.5\n",
    "WEIGHT_DECAY = 0.0001 # L2 regularization\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(\"Created DataLoaders Successfully!\")\n",
    "\n",
    "model = ExpoNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay= WEIGHT_DECAY)\n",
    "model.trainEpochs(criterion, optimizer, train_dataloader, val_dataloader, num_epochs=EPOCHS, lr_decay=LR_DECAY, lr_decay_epoch=LR_DECAY_EPOCH, lr_decay_factor=LR_DECAY_FACTOR)\n",
    "model.test(test_dataloader)\n",
    "modelParams = f\"models/ExpoNet_BATCHSIZE{BATCH_SIZE}_LR_{LEARNING_RATE}_Nfft{N_FFT}_hopsize_{HOP_SIZE}_nmels_{N_MELS}_epochs_{EPOCHS}_lr_decay_{LR_DECAY}_lr_decay_epoch_{LR_DECAY_EPOCH}_lr_decay_factor_{LR_DECAY_FACTOR}_weight_decay_{WEIGHT_DECAY}.pth\"\n",
    "torch.save(model.state_dict(), modelParams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
